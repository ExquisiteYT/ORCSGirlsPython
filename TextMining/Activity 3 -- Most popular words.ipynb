{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/PoweredTechGirlz.png\" width=\"15%\" align=\"right\">\n",
    "\n",
    "# Activity 3: Text Mining Harry Potter - Most Popular Words\n",
    "\n",
    "We will be using data provided by [Bradley Boehmke](https://github.com/bradleyboehmke/harrypotter).\n",
    "\n",
    "The goal of this class is to do a textual analysis of the seven Harry Potter books. We will use Python to discover some interesting insights that maybe nobody else in the world has realized about the Harry Potter books! In this activity we will find the most popular words and combination of words in book 1.\n",
    "\n",
    "<img src=\"Images/book_covers.png\" width=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import Helpers\n",
    "from Helpers.load_data import *\n",
    "from Helpers.plot_data import *\n",
    "from Helpers.clean_data import *\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Most popular words\n",
    "\n",
    "## Clean up\n",
    "\n",
    "We will try to find out which words are the most popular in each book.\n",
    "\n",
    "We already know how to split each book into words, but this time we will need to do two additional steps.\n",
    "\n",
    "First, look at the following piece of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = (\n",
    "    \"Hagrid: \\\"You're a wizard, Harry\\\" \"\n",
    "    \"Harry: \\\"I am a what?\\\" \"\n",
    "    \"Hagrid: \\\"A wizard, Harry\\\" \"\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we find the most popular words in this piece of text?\n",
    "\n",
    "As it turns out, Python has another neat function which we can use to do that. It's called a `Counter`. You can give `Counter` a list of words and it will count how many times does each word appear. \n",
    "\n",
    "To do that, we first need a list of words. In the cell below, split the text into words and assign the result to a new variable called `words`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have separate words, we can pass those to a `Counter`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened? `Counter` counted the words \"Harry\" and \"Harry:\" as two separate words. It also counted \"A\" and \"a\" as two separate words.\n",
    "\n",
    "To fix this, we will need to remove all characters from the text which are not letters, and conver the text to lowercase.\n",
    "\n",
    "First, lets convert the words to lowercase. In Python that can be done using a function called `lower`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HELLO\".lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do this for the words in our text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_words = []\n",
    "\n",
    "for word in words:\n",
    "    lowercase_words.append(word.lower())\n",
    "    \n",
    "print(lowercase_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try the counter again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(lowercase_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still have some special character in the text (like ':' and '\"') that make Python think '\"a' and 'a' are two separate words. We prepared a helper function that you can use to remove those special characters. It's called `remove_special_characters` :) This is how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_word = '\"Harry!\"'\n",
    "\n",
    "print(\"Original word:\", my_word)\n",
    "\n",
    "clean_word = remove_special_characters(my_word)\n",
    "\n",
    "print(\"Clean word:\", clean_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you do this for all words in our text? Try to do that in the field below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = []\n",
    "\n",
    "for word in lowercase_words:\n",
    "    clean_words.append(remove_special_characters(word))\n",
    "    \n",
    "print(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the counter again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(clean_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular words\n",
    "\n",
    "Let's try to apply this to the first book. First, let's load the book and split it to words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1 = load_book_1()\n",
    "\n",
    "words = book_1.split()\n",
    "\n",
    "print(words[0:26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do what we just learned: turn all words to lowercase and remove special characters. We can do this in one go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_words = []\n",
    "\n",
    "for word in words:\n",
    "    lowercase_word = word.lower()\n",
    "    clean_word = remove_special_characters(lowercase_word)\n",
    "    clean_words.append(clean_word)\n",
    "    \n",
    "print(clean_words[0:26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just cleaned the whole book one!\n",
    "\n",
    "We can use `Counter` to count occurences of all words in the book!\n",
    "\n",
    "The list would be veeeeeeeeeeery long! So let's ask counter to only give us the 10 most common words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(clean_words).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# That's it! The 10 most common words in book 1!\n",
    "\n",
    "Something happened though. Are all of the words useful to us? Is it useful knowing that \"the\" is the most common word?\n",
    "\n",
    "In English, words like \"the\", \"a\", and \"I\" appear very often, but don't give us any useful information. The frequently appearing words are called \"stopwords\". They are important because they help to structure our sentences, but they don't tell us anything about the meaning of the text.\n",
    "\n",
    "That's why in Text Mining we usually remove those words.\n",
    "\n",
    "We prepared another helper function that you can use -- this function removes all stopwords from a list of words. It's called `remove_stopwords`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Before:\", clean_words[0:26])\n",
    "print()\n",
    "\n",
    "no_stopwords = remove_stopwords(clean_words)\n",
    "\n",
    "print(\"After:\", no_stopwords[0:26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the `Counter` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(no_stopwords).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yay! That worked!\n",
    "\n",
    "Can you tell me who are the most frequently mentioned students in book 1?\n",
    "\n",
    "Let's try to do this for book 2!\n",
    "\n",
    "We prepared a bit of code to help you. Fill in the missing lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_2 = load_book_2()\n",
    "\n",
    "words = book_2.split()\n",
    "\n",
    "clean_words = []\n",
    "\n",
    "for word in words:\n",
    "    lowercase_word = word.lower()\n",
    "    clean_word = remove_special_characters(lowercase_word)\n",
    "    clean_words.append(clean_word)\n",
    "    \n",
    "no_stopwords = remove_stopwords(clean_words)\n",
    "\n",
    "Counter(no_stopwords).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that in the previous activity we used a function called `plot` to visualize the results? Let's try that again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_words = Counter(no_stopwords).most_common(10)\n",
    "\n",
    "plot_words(top_10_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word pairs\n",
    "\n",
    "What about combinations of words?\n",
    "\n",
    "So far we were looking at a single word at a time. What if we want to find how often do two words appear in the text together? For example \"professor lockhart\".\n",
    "\n",
    "Remember our text from the start of this activity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split it to words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.split()\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gives us single words.\n",
    "\n",
    "We prepared a function which takes a list of words and turns those words into pairs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_word_pairs(words)\n",
    "\n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(pairs).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let's do this for book 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1 = load_book_1()\n",
    "\n",
    "words = book_1.split()\n",
    "\n",
    "clean_words = []\n",
    "\n",
    "for word in words:\n",
    "    lowercase_word = word.lower()\n",
    "    clean_word = remove_special_characters(lowercase_word)\n",
    "    clean_words.append(clean_word)\n",
    "    \n",
    "no_stopwords = remove_stopwords(clean_words)\n",
    "\n",
    "word_pairs = get_word_pairs(no_stopwords)\n",
    "\n",
    "Counter(word_pairs).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_words(Counter(word_pairs).most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yeak you made it through activity 3.\n",
    "\n",
    "Feel free to experiment with the notebook to learn even more about the Harry Potter books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
