{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tproffen/ORCSGirlsPython/blob/master/TextMining/Activity%202%20--%20Book%20length.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/tproffen/ORCSGirlsPython/blob/master/TextMining/Images/PoweredTechGirlz.png?raw=1\" width=\"15%\" align=\"right\">\n",
    "\n",
    "# Activity 5: Text Mining Harry Potter - Sentiment Analysis\n",
    "\n",
    "We will be using data provided by [Bradley Boehmke](https://github.com/bradleyboehmke/harrypotter).\n",
    "\n",
    "The goal of this class is to do a textual analysis of the seven Harry Potter books. We will use Python to discover some interesting insights that maybe nobody else in the world has realized about the Harry Potter books!\n",
    "\n",
    "These are the books we will be analyzing:\n",
    "\n",
    "1. Harry Potter and the Sorcerer's Stone\n",
    "2. Harry Potter and the Chamber of Secrets\n",
    "3. Harry Potter and the Prisoner of Azkaban\n",
    "4. Harry Potter and the Goblet of Fire\n",
    "5. Harry Potter and the Order of the Phoenix\n",
    "6. Harry Potter and the Half-Blood Prince\n",
    "7. Harry Potter and the Deathly Hallows\n",
    "\n",
    "<img src=\"https://github.com/tproffen/ORCSGirlsPython/blob/master/TextMining/Images/book_covers.png?raw=1\" width=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to import the helper functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -o setup.sh https://raw.githubusercontent.com/tproffen/ORCSGirlsPython/master/TextMining/Helpers/setup_activity2.sh\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import Helpers\n",
    "from Helpers.load_data import *\n",
    "from Helpers.plot_data import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We talked about how sentiment analysis is done using machine learning. Fortunately for us, others have created libraries in Python which already contain ready to use machine learning models for sentiment detection. The library we will be using is called [VADER](https://github.com/cjhutto/vaderSentiment).\n",
    "\n",
    "Let's first create a list of sentences to test sentiment analysis on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Our Saturday classes and fun and super interesting!\",\n",
    "    \"Make sure you :) or :D today!\",\n",
    "    \"The book was great, I enjoyed it very much.\",\n",
    "    \"At least it isn't a horrible book.\",\n",
    "    \"I got a very bad grade on my homework.\",\n",
    "    \"Today is a really terrible day :(\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use VADER to get sentiment of these sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this imports the library we need\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# this line just creates a sentiment model\n",
    "sentiment_model = SentimentIntensityAnalyzer()\n",
    "\n",
    "# now we will iterate over all sentences and get their sentiment\n",
    "for sentence in sentences:\n",
    "    \n",
    "    # get sentiment\n",
    "    scores = sentiment_model.polarity_scores(sentence)\n",
    "    \n",
    "    # print the sentence and sentiment\n",
    "    print(sentence)\n",
    "    \n",
    "    # the {: <15} characters just tell python to add spaces between columns\n",
    "    print(\"negative: {: <15} neutral: {: <15} positive: {: <15} compound: {}\\n\".format(\n",
    "        scores['neg'], scores['neu'], scores['pos'], scores['compound']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! We have just applied a machine learning model to text and had it predict sentiment.\n",
    "\n",
    "What if you change some words or add negation?\n",
    "\n",
    "Try to add some of your own sentences to this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment of Book 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to get sentiment of sentences. What if we want to apply the model to a whole book? We will need to load the book and split it to sentences.\n",
    "\n",
    "We already know how to load a book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1 = load_book_1()\n",
    "\n",
    "# print the first 500 characters of book 1\n",
    "print(book_1[0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we would like to know what's the sentiment of each chapter.\n",
    "\n",
    "We prepared a helper function that splits the book into chapters. The function returns two lists:\n",
    "* A list of chapters found in book 1\n",
    "* A list of chapter names (so that we can create a pretty plot:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1_chapters, book_1_chapter_names = load_book_1_chapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# how many chapters are there?\n",
    "print(len(book_1_chapters))\n",
    "\n",
    "# print the chapter names\n",
    "print(book_1_chapter_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(book_1_chapters[16][0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to split each chapter into sentences. Fortunately, as with many things in Python, there is a handy library that we can use to do that :) The library is called NLTK.\n",
    "\n",
    "NLTK has a function `sent_tokenize` which works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NLTK, a library for text mining in Python\n",
    "from nltk import sent_tokenize\n",
    "\n",
    "# let's get sentences from the first chapter\n",
    "# remember that Python indexes lists from 0, so the first chapter has index 0\n",
    "sentences = sent_tokenize(book_1_chapters[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you print the first 10 sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your code to print the first 10 sentences from the first chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know how to get sentiment of sentences. Let's print the sentiment of the first 5 sentences from chapter 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_model = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in sentences[0:5]:\n",
    "    \n",
    "    scores = sentiment_model.polarity_scores(sentence)\n",
    "    \n",
    "    print(sentence)\n",
    "    \n",
    "    print(\"negative: {: <15} neutral: {: <15} positive: {: <15} compound: {}\\n\".format(\n",
    "        scores['neg'], scores['neu'], scores['pos'], scores['compound']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to know whare are the most positive and negative sentences in a chapter? We can save scores for all sentences into a list and then sort them. We prepared a code to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    \n",
    "    scores = sentiment_model.polarity_scores(sentence)\n",
    "    \n",
    "    all_scores.append([sentence, scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the top 10 most positive sentences from chapter 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for sentence, scores in sorted(all_scores, key=lambda x: x[1]['pos'], reverse=True)[:10]:\n",
    "    print(sentence)\n",
    "    \n",
    "    print(\"negative: {: <15} neutral: {: <15} positive: {: <15} compound: {}\\n\".format(\n",
    "        scores['neg'], scores['neu'], scores['pos'], scores['compound']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print the top 10 negative sentences from chapter 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence, scores in sorted(all_scores, key=lambda x: x[1]['neg'], reverse=True)[:10]:\n",
    "    print(sentence)\n",
    "    \n",
    "    print(\"negative: {: <15} neutral: {: <15} positive: {: <15} compound: {}\\n\".format(\n",
    "        scores['neg'], scores['neu'], scores['pos'], scores['compound']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to get sentiment of sentences, let's find sentiment of each chapter in the book and create a plot!\n",
    "\n",
    "We will do the following:\n",
    "    \n",
    "* Split each chapter in book 1 into sentences\n",
    "* Get compound sentiment score of each sentence\n",
    "* Calculate the sentiment score of a chapter as the **average value of sentiment of all sentences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# let's store sentiment scores for each chapter in a list\n",
    "chapter_scores = []\n",
    "\n",
    "for chapter in book_1_chapters:\n",
    "    \n",
    "    sentences = sent_tokenize(chapter)\n",
    "    \n",
    "    # to calculate average score, we will first store scores for all sentences\n",
    "    all_scores = []    \n",
    "    for sentence in sentences:\n",
    "        scores = sentiment_model.polarity_scores(sentence)\n",
    "        compound_score = scores['compound']\n",
    "        all_scores.append(compound_score)\n",
    "\n",
    "    # average is calculated as sum of all scores divided by number of scores\n",
    "    chapter_score = sum(all_scores) / len(all_scores)\n",
    "    chapter_scores.append(chapter_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print the scores along with names of each chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(zip(book_1_chapter_names, chapter_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We prepared a helper function that you can use to plot the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_book_scores(book_1_chapter_names, chapter_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the scores what you would expect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment of all books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to do the same for all books.\n",
    "\n",
    "We prepared a helper function for loading all chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_chapters, all_names = load_all_chapters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_chapter_scores = []\n",
    "\n",
    "for book_number, book_chapters in enumerate(all_chapters):\n",
    "    \n",
    "    chapter_scores = []\n",
    "    \n",
    "    for chapter_number, chapter in enumerate(book_chapters):\n",
    "    \n",
    "        sentences = sent_tokenize(chapter)\n",
    "\n",
    "        all_scores = []    \n",
    "        for sentence in sentences:\n",
    "            scores = sentiment_model.polarity_scores(sentence)\n",
    "            compound_score = scores['compound']\n",
    "            all_scores.append(compound_score)\n",
    "\n",
    "        # average is calculated as sum of all scores divided by number of scores\n",
    "        chapter_score = sum(all_scores) / len(all_scores)\n",
    "        chapter_scores.append(chapter_score)\n",
    "        \n",
    "    all_chapter_scores.append(chapter_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_book_scores(all_names, all_chapter_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
