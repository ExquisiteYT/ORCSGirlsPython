{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/tproffen/ORCSGirlsPython/blob/master/TextMining/Activity%202%20--%20Book%20length.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/tproffen/ORCSGirlsPython/blob/master/TextMining/Images/PoweredTechGirlz.png?raw=1\" width=\"15%\" align=\"right\">\n",
    "\n",
    "# Activity 6: Text Mining Harry Potter - Sentiment Analysis\n",
    "\n",
    "We will be using data provided by [Bradley Boehmke](https://github.com/bradleyboehmke/harrypotter).\n",
    "\n",
    "The goal of this class is to do a textual analysis of the seven Harry Potter books. We will use Python to discover some interesting insights that maybe nobody else in the world has realized about the Harry Potter books!\n",
    "\n",
    "These are the books we will be analyzing:\n",
    "\n",
    "1. Harry Potter and the Sorcerer's Stone\n",
    "2. Harry Potter and the Chamber of Secrets\n",
    "3. Harry Potter and the Prisoner of Azkaban\n",
    "4. Harry Potter and the Goblet of Fire\n",
    "5. Harry Potter and the Order of the Phoenix\n",
    "6. Harry Potter and the Half-Blood Prince\n",
    "7. Harry Potter and the Deathly Hallows\n",
    "\n",
    "<img src=\"https://github.com/tproffen/ORCSGirlsPython/blob/master/TextMining/Images/book_covers.png?raw=1\" width=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to import the helper functions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -o setup.sh https://raw.githubusercontent.com/tproffen/ORCSGirlsPython/master/TextMining/Helpers/setup_activity2.sh\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Helpers\n",
    "from Helpers.load_data import *\n",
    "from Helpers.plot_data import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have been working with individual words and short phrases. For detecting sentiment, we will need to split the text of the books to sentences. Fortunately, as always, there is an easy way to do that in Python:) But first, we will see how sentiment detection works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Our Saturday classes and fun and super interesting!\",\n",
    "    \"Make sure you :) or :D today!\",\n",
    "    \"The book was great, I enjoyed it very much.\",\n",
    "    \"At least it isn't a horrible book.\",\n",
    "    \"I got a very bad grade on my homework.\",\n",
    "    \"Today is a really terrible day :(\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    scores = analyzer.polarity_scores(sentence)\n",
    "    print(\"{:-<55} neg: {: <5}, neu: {: <5}, pos: {: <5}\".format(\n",
    "        sentence, scores['neg'], scores['neu'], scores['pos']\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's apply what we just did to book 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1 = load_book_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/chapters.json') as fp_in:\n",
    "    chapters = json.load(fp_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1_chapters = {}\n",
    "previous_chapter = chapters['01'][0]\n",
    "previous_chapter_loc = len(previous_chapter) + 1\n",
    "for c in chapters['01'][1:]:\n",
    "    chapter_loc = book_1.index(c)\n",
    "    book_1_chapters[previous_chapter] = book_1[previous_chapter_loc:chapter_loc]\n",
    "    previous_chapter_loc = chapter_loc + len(c)\n",
    "    previous_chapter = c\n",
    "book_1_chapters[c] = book_1[previous_chapter_loc:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_1_chapters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(book_1_chapters['THE MAN WITH TWO FACES'][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(book_1_chapters['THE BOY WHO LIVED'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for sentence in sentences:\n",
    "    scores = analyzer.polarity_scores(sentence)\n",
    "    all_scores.append([sentence, scores])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted(all_scores, key=lambda x: x[1]['pos'], reverse=True)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
